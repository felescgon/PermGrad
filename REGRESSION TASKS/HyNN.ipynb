{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EybOZ6hSjpCF"
   },
   "source": [
    "<h1><font color=\"#113D68\" size=6>PermGrad: Interpretable Hybrid Neural Networks with Synthetic Images for Tabular Data</font></h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwYF5A2njpC8"
   },
   "source": [
    "# <font color=\"#004D7F\" size=6> 1. Libraries</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hy5okt4cpiud"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 1.1. System setup</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    sudo pip3 install tensorflow==2.17.1 torchmetrics pytorch_lightning TINTOlib==0.0.26 imblearn keras_preprocessing mpi4py bitstring optuna\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2_nqaiEpiuf"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 1.2. Invoke the libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeeBbGxlpjFp"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    MaxPooling2D,\n",
    "    BatchNormalization,\n",
    "    Input,\n",
    "    Concatenate,\n",
    ")\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras.initializers import (\n",
    "    HeNormal,\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Lambda\n",
    ")\n",
    "from tensorflow.keras.models import (\n",
    "    Model,\n",
    "    load_model\n",
    ")\n",
    "from TINTOlib.tinto import TINTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDL4LARWjpDT"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=6> 2. Data processing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLzynCxOpHBX"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 2.1. TINTOlib methods</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYHscfDgpiug"
   },
   "outputs": [],
   "source": [
    "dataset = \"Puma\"\n",
    "pixels=20\n",
    "problem_type = \"regression\"\n",
    "\n",
    "images_folder = f\"../images/{dataset}\"\n",
    "image_model = TINTO(problem= problem_type,blur=False, pixels=pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtHDA1vxpiug"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 2.2. Read the dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTaF1qYSx8IS"
   },
   "outputs": [],
   "source": [
    "if dataset == \"Puma\":\n",
    "  dataset_path = \"../datasets/PUMA/puma8NH.csv\"\n",
    "  df=pd.read_csv(dataset_path, delimiter=',')\n",
    "  df\n",
    "  df_x = df.drop('values', axis = 1)\n",
    "  df_y = df['values']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9CnSiM5pium"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 2.3. Generate images</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k030GjgEpium"
   },
   "outputs": [],
   "source": [
    "force_recreate_images = True\n",
    "\n",
    "if not os.path.exists(images_folder) or force_recreate_images:\n",
    "    image_model.generateImages(df, images_folder)\n",
    "else:\n",
    "    print(\"The images are already generated\")\n",
    "\n",
    "img_paths = os.path.join(images_folder,problem_type+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klS9PZsUjpDV"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 2.4. Read images</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ql1JjflBtff"
   },
   "outputs": [],
   "source": [
    "imgs = pd.read_csv(img_paths)\n",
    "imgs[\"images\"]= images_folder + \"/\" + imgs[\"images\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2nFqiJpPvwf"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 2.5. Preprocess the dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDcHEOeIPuBf"
   },
   "outputs": [],
   "source": [
    "columns_to_normalize = df.drop(columns='values').columns\n",
    "\n",
    "df_normalized = (df[columns_to_normalize] - df[columns_to_normalize].min()) / (df[columns_to_normalize].max() - df[columns_to_normalize].min())\n",
    "\n",
    "df = pd.concat([df_normalized, df['values']], axis=1)\n",
    "\n",
    "df_normalized.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1757267483545,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "gGGoc-CT9vpn",
    "outputId": "39208dac-9a04-44b6-adcf-153703a37599"
   },
   "outputs": [],
   "source": [
    "combined_dataset = pd.concat([imgs,df.iloc[:, :-1]],axis=1)\n",
    "\n",
    "df_x = combined_dataset\n",
    "df_y = df[\"values\"]\n",
    "\n",
    "print(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoEeYhAtpiun"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=6> 3. Pre-modelling phase</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nb4Dd37rjpDm"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 3.1. Data curation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1757267484056,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "BDyHty4-pjF5",
    "outputId": "be90e655-b801-423c-a26c-ace30eb14603"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size = 0.40, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.50, random_state = 42)\n",
    "\n",
    "X_train_num = X_train.drop(\"images\",axis=1)\n",
    "X_val_num = X_val.drop(\"images\",axis=1)\n",
    "X_test_num = X_test.drop(\"images\",axis=1)\n",
    "\n",
    "X_train_img = np.array([cv2.resize(cv2.imread(img),(pixels,pixels)) for img in X_train[\"images\"]])\n",
    "X_val_img = np.array([cv2.resize(cv2.imread(img),(pixels,pixels)) for img in X_val[\"images\"]])\n",
    "X_test_img = np.array([cv2.resize(cv2.imread(img),(pixels,pixels)) for img in X_test[\"images\"]])\n",
    "\n",
    "print(\"Image shape\",X_train_img[0].shape)\n",
    "size=X_train_img[0].shape[0]\n",
    "print(\"Image size (pixels):\", pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5QkishzCEL7"
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis = 1)\n",
    "df_test = pd.concat([X_test, y_test], axis = 1)\n",
    "df_val = pd.concat([X_val, y_val], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1757267484063,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "ebOBC5iypjGA",
    "outputId": "eaa8242f-3253-4dd9-ebd1-5b282edbf0bb"
   },
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE0VunQYjpEY"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=6> 4. Modelling with HyNN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn2U90FwjpEe"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 4.1. HyNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_checkpoint_dir = f'../models/{dataset}/optuna_checkpoints'\n",
    "\n",
    "model_path = f'../models/{dataset}/model_{dataset}_hybrid.keras'\n",
    "\n",
    "study_db_path = f'../models/{dataset}/study_{dataset}_hybrid.db'\n",
    "\n",
    "storage_url = f\"sqlite:///{study_db_path}\"\n",
    "study_name = f\"{dataset}_hybrid_study\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZl0AETUw1r8"
   },
   "outputs": [],
   "source": [
    "def create_multimodal_regressor(trial, shape, pixels):\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.4)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    n_dense_layers = trial.suggest_int(\"n_dense_layers\", 1, 4)\n",
    "    n_conv_layers = trial.suggest_int(\"n_conv_layers\", 1, 4)\n",
    "    base_filters = trial.suggest_int(\"base_filters\", 8, 256)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"adamw\"])\n",
    "    activation_fn = trial.suggest_categorical(\"activation\", [\"relu\"])\n",
    "\n",
    "    init_name = trial.suggest_categorical(\"initializer\", [\"he_normal\"])\n",
    "    if init_name == \"he_normal\":\n",
    "        initializer = HeNormal()\n",
    "\n",
    "    ff_inputs = Input(shape=(shape,))\n",
    "    x_tab = ff_inputs\n",
    "    for i in range(n_dense_layers):\n",
    "        units = trial.suggest_int(f\"dense_units_{i}\", 8, 256)\n",
    "        x_tab = Dense(units, activation=activation_fn, kernel_initializer=initializer)(x_tab)\n",
    "        x_tab = BatchNormalization()(x_tab)\n",
    "        x_tab = Dropout(dropout)(x_tab)\n",
    "    ff_model = Model(ff_inputs, x_tab)\n",
    "\n",
    "    cnn_inputs = Input(shape=(pixels, pixels, 3))\n",
    "    x_cnn = cnn_inputs\n",
    "\n",
    "    for i in range(n_conv_layers):\n",
    "        filters = int(base_filters * (2 ** i))\n",
    "        x_cnn = Conv2D(filters, (3, 3), activation=activation_fn, padding='same', kernel_initializer=initializer)(x_cnn)\n",
    "        x_cnn = BatchNormalization()(x_cnn)\n",
    "        x_cnn = MaxPooling2D(2, 2)(x_cnn)\n",
    "        x_cnn = Dropout(dropout)(x_cnn)\n",
    "    x_cnn = Flatten()(x_cnn)\n",
    "    cnn_model = Model(cnn_inputs, x_cnn)\n",
    "\n",
    "    combined = Concatenate()([ff_model.output, cnn_model.output])\n",
    "    x_conc = combined\n",
    "    for i in range(n_dense_layers):\n",
    "        units = trial.suggest_int(f\"combined_dense_units_{i}\", 8, 256)\n",
    "        x_conc = Dense(units, activation=activation_fn, kernel_initializer=initializer)(x_conc)\n",
    "        x_conc = BatchNormalization()(x_conc)\n",
    "        x_conc = Dropout(dropout)(x_conc)\n",
    "\n",
    "    output = Dense(1, activation='linear', kernel_initializer=initializer)(x_conc)\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    else:\n",
    "        wd = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "        opt = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
    "\n",
    "    model = Model(inputs=[ff_model.input, cnn_model.input], outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='mean_squared_error',\n",
    "        metrics=[\n",
    "            tf.keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "            tf.keras.metrics.MeanSquaredError(name='mse'),\n",
    "            tf.keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "            tf.keras.metrics.MeanAbsolutePercentageError(name='mape'),\n",
    "            tf.keras.metrics.R2Score(name='r2_score'),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def one_cycle_schedule(epoch, lr, total_epochs, max_lr, min_lr=1e-5):\n",
    "    if epoch < total_epochs * 0.25:\n",
    "        return min_lr + (max_lr - min_lr) * (epoch / (total_epochs * 0.25))\n",
    "    else:\n",
    "        progress = (epoch - total_epochs * 0.25) / (total_epochs * 0.75)\n",
    "        return max_lr * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    os.makedirs(base_checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(base_checkpoint_dir, f\"trial_{trial.number}_best_model.keras\")\n",
    "\n",
    "    shape = len(X_train_num.columns)\n",
    "    pixels = X_train_img.shape[1]\n",
    "\n",
    "    model = create_multimodal_regressor(trial, shape, pixels)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32])\n",
    "    epochs = 200\n",
    "\n",
    "    max_lr = trial.params.get(\"lr\", 1e-2)\n",
    "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "        lambda epoch, lr: one_cycle_schedule(epoch, lr, total_epochs=epochs, max_lr=max_lr),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='min',\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=6, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        [X_train_num, X_train_img], y_train,\n",
    "        validation_data=([X_val_num, X_val_img], y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping, checkpoint_cb, lr_scheduler]\n",
    "    )\n",
    "\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    trial.set_user_attr(\"best_model_path\", checkpoint_path)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 4.2. Compile and fit</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZvPPESmpivH"
   },
   "outputs": [],
   "source": [
    "force_retrain = True\n",
    "\n",
    "if not os.path.exists(model_path) or force_retrain:\n",
    "\n",
    "    print(f\"Creating or loading study: {study_name} from {study_db_path}\")\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage_url,\n",
    "        direction=\"minimize\",\n",
    "        load_if_exists=True\n",
    "    )\n",
    "\n",
    "    n_total_trials = 75\n",
    "    print(f\"Current trials: {len(study.trials)}. Optimizing up to {n_total_trials} total trials.\")\n",
    "    study.optimize(objective, n_trials=(n_total_trials - len(study.trials)))\n",
    "\n",
    "    print(\"\\nOptimization complete. Best trial:\")\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"  Value (val_loss): {best_trial.value}\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    best_model_path = best_trial.user_attrs[\"best_model_path\"]\n",
    "    print(f\"Loading best model from: {best_model_path}\")\n",
    "    best_model = load_model(best_model_path)\n",
    "\n",
    "    best_model.save(model_path)\n",
    "    model = best_model\n",
    "    print(f\"Best model saved to: {model_path}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Model already exists at {model_path}. Loading it.\")\n",
    "    model = load_model(model_path)\n",
    "\n",
    "print(\"Process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    expand_nested=True,\n",
    "    dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R2jytfijpEp"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=6> 5. Results</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQq3wYejpivM"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=5> 5.1. Validation/Test evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2297,
     "status": "ok",
     "timestamp": 1757267488835,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "MtDLUW_QpjGO",
    "outputId": "8ce78afb-5866-4d9f-c2d8-31207dd50d35"
   },
   "outputs": [],
   "source": [
    "score_test = model.evaluate([X_val_num, X_val_img], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test = model.evaluate([X_test_num, X_test_img], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1757267489641,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "27tFyGE8pjGO",
    "outputId": "87cffa14-cb65-4555-9970-76b9c88187c5"
   },
   "outputs": [],
   "source": [
    "score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8GRJuLKpivT"
   },
   "source": [
    "---\n",
    "# <font color=\"#004D7F\" size=6> 6. PermGrad Framework application</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrLAXmDX91tq"
   },
   "source": [
    "---\n",
    "## <font color=\"#004D7F\" size=6> 6.1. Permutation Feature Importance - MLP</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhpMIU9zU0KK"
   },
   "outputs": [],
   "source": [
    "def plot_feature_importance_bar(feature_importance, title, output_path, top_n=10):\n",
    "    sorted_features = sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    top_features_list = sorted_features[:top_n]\n",
    "\n",
    "    features, importances = zip(*top_features_list)\n",
    "    print(f\"Top {top_n} Features: {dict(top_features_list)}\")\n",
    "\n",
    "    y_positions = np.arange(len(features))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    cmap = plt.get_cmap(\"Accent\")\n",
    "    colors = [cmap(0)] * len(sorted_features)\n",
    "\n",
    "    plt.barh(\n",
    "        y_positions,\n",
    "        importances,\n",
    "        height=0.8,\n",
    "        color=colors,\n",
    "        edgecolor='white'\n",
    "    )\n",
    "\n",
    "    plt.axvline(x=0, color='grey', linestyle='--', linewidth=0.8)\n",
    "    plt.ylabel(\"Features\", fontsize=18)\n",
    "    plt.xlabel(\"Feature Importance\", fontsize=18)\n",
    "    if title != \"\":\n",
    "        plt.title(f\"{title}\", fontsize=18)\n",
    "\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(y_positions, [k for k,_ in sorted_features], size=14)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1757269054748,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "MoNyXmGw-YPq",
    "outputId": "f21031de-1a47-477d-96d6-041d8e300541"
   },
   "outputs": [],
   "source": [
    "if dataset == \"Puma\":\n",
    "  dataset_path = f\"../datasets/{dataset}\"\n",
    "  mlp_importances_named_path = f'{dataset_path}/mlp_metrics.npy'\n",
    "\n",
    "n_repeats = 5\n",
    "\n",
    "if not os.path.exists(mlp_importances_named_path):\n",
    "    y_pred = model.predict([X_test_num, X_test_img], verbose=0).ravel()\n",
    "    baseline_loss = tf.keras.losses.MSE(y_test, y_pred).numpy().mean()\n",
    "\n",
    "    mlp_importances = {}\n",
    "\n",
    "    for feature in tqdm(X_test_num.columns, desc=\"Permuting features\"):\n",
    "        deltas = []\n",
    "\n",
    "        for _ in range(n_repeats):\n",
    "            X_perm = X_test_num.copy()\n",
    "            X_perm[feature] = np.random.permutation(X_perm[feature].values)\n",
    "\n",
    "            y_pred_perm = model.predict([X_perm, X_test_img], verbose=0).ravel()\n",
    "\n",
    "            loss_perm = tf.keras.losses.MSE(y_test, y_pred_perm).numpy().mean()\n",
    "            deltas.append(loss_perm - baseline_loss)\n",
    "\n",
    "        mlp_importances[feature] = np.mean(deltas)\n",
    "\n",
    "    np.save(mlp_importances_named_path, mlp_importances, allow_pickle=True)\n",
    "\n",
    "else:\n",
    "    mlp_importances = np.load(mlp_importances_named_path, allow_pickle=True).item()\n",
    "\n",
    "print(f\"\\n=== MLP‐branch ΔMSE per feature (averaged over {n_repeats} repeats) ===\")\n",
    "for f, imp in mlp_importances.items():\n",
    "    print(f\"{f}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1757269055204,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "ob2yBcGmBjPX",
    "outputId": "ec18cfb8-1641-4bfa-e03b-25e10d99c0be"
   },
   "outputs": [],
   "source": [
    "mlp_importances = {f: (v.numpy() if hasattr(v, \"numpy\") else v) for f, v in mlp_importances.items()}\n",
    "\n",
    "min_val, max_val = min(mlp_importances.values()), max(mlp_importances.values())\n",
    "mlp_importances_normalized = {f: (v - min_val) / (max_val - min_val) for f, v in mlp_importances.items()}\n",
    "\n",
    "plot_feature_importance_bar(mlp_importances_normalized, title=\"\", output_path = f'{dataset_path}/mlp_metrics.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zLyxvTNCZvX"
   },
   "source": [
    "---\n",
    "## <font color=\"#004D7F\" size=6> 6.2. Grad-CAM Heatmap Feature Importance - CNN</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "executionInfo": {
     "elapsed": 853,
     "status": "ok",
     "timestamp": 1757269056058,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "qoue2QDeClAf",
    "outputId": "0fb1a671-9638-43ff-9469-513a353b076c"
   },
   "outputs": [],
   "source": [
    "def cuadrado(coord):\n",
    "    m = np.mean(coord, axis=0).reshape((1, 2))\n",
    "    coord_nuevo = coord - m\n",
    "    dista = (coord_nuevo[:, 0]**2 + coord_nuevo[:, 1]**2)**0.5\n",
    "    maxi = math.ceil(max(dista))\n",
    "    vertices = np.array([[-maxi, maxi], [-maxi, -maxi], [maxi, -maxi], [maxi, maxi]])\n",
    "    coord_nuevo = coord_nuevo - vertices[0]\n",
    "    vertices = vertices - vertices[0]\n",
    "    return coord_nuevo, vertices\n",
    "\n",
    "def m_imagen(coord, vertices, pixeles=20):\n",
    "    size = (pixeles, pixeles)\n",
    "    matriz = np.zeros(size)\n",
    "    coord_m = (coord / vertices[2, 0]) * (pixeles - 1)\n",
    "    coord_m = np.round(abs(coord_m))\n",
    "    for i, j in zip(coord_m[:, 1], coord_m[:, 0]):\n",
    "        matriz[int(i), int(j)] = 1\n",
    "    if np.count_nonzero(matriz != 0) != coord.shape[0]:\n",
    "        return coord_m, matriz, True\n",
    "    else:\n",
    "        return coord_m, matriz, False\n",
    "\n",
    "\n",
    "class DataImg:\n",
    "    def __init__(self, algoritmo='PCA', pixeles=20, seed=20, veces=4, amp=np.pi, distancia=0.1, pasos=4, opcion='maximo'):\n",
    "        self.algoritmo = algoritmo\n",
    "        self.p = pixeles\n",
    "        self.seed = seed\n",
    "        self.veces = veces\n",
    "\n",
    "        self.amp = amp\n",
    "        self.distancia = distancia\n",
    "        self.pasos = pasos\n",
    "        self.opcion = opcion\n",
    "\n",
    "        self.error_pos = False\n",
    "\n",
    "    def ObtenerCoord(self, X):\n",
    "        self.min_max_scaler = MinMaxScaler()\n",
    "        X = self.min_max_scaler.fit_transform(X)\n",
    "        labels = np.arange(X.shape[1])\n",
    "        X_trans = X.T\n",
    "\n",
    "\n",
    "        if(self.algoritmo=='PCA'):\n",
    "            X_embedded = PCA(n_components=2,random_state=self.seed).fit(X_trans).transform(X_trans)\n",
    "        elif(self.algoritmo=='t-SNE'):\n",
    "            for _ in range(self.veces):\n",
    "                X_trans = np.append(X_trans,X_trans,axis=0)\n",
    "                labels = np.append(labels,labels,axis=0)\n",
    "            X_embedded = TSNE(n_components=2,random_state=self.seed,perplexity=50).fit_transform(X_trans)\n",
    "        else:\n",
    "            X_embedded = np.random.rand(X.shape[1],2)\n",
    "\n",
    "        datos_coordenadas = {'x':X_embedded[:,0], 'y':X_embedded[:,1], 'Sector':labels}\n",
    "        dc = pd.DataFrame(data=datos_coordenadas)\n",
    "        self.coord_obtenidas = dc.groupby('Sector').mean().values\n",
    "\n",
    "        del X_trans\n",
    "        gc.collect()\n",
    "\n",
    "    def Delimitacion(self):\n",
    "        self.coordenadas_iniciales, self.vertices = cuadrado(self.coord_obtenidas)\n",
    "\n",
    "    def ObtenerMatrizPosiciones(self, columns_names):\n",
    "        self.pos_pixel_caract, self.m, self.error_pos = m_imagen(self.coordenadas_iniciales,self.vertices,pixeles=self.p)\n",
    "        self.columns_coords = dict()\n",
    "\n",
    "        for coord, column_name in zip(self.pos_pixel_caract, columns_names):\n",
    "          self.columns_coords[column_name] = coord\n",
    "\n",
    "        print(self.columns_coords)\n",
    "\n",
    "    def Entrenamiento(self, X, columns_names):\n",
    "        self.columns_names = columns_names\n",
    "        self.ObtenerCoord(X)\n",
    "        self.Delimitacion()\n",
    "        self.ObtenerMatrizPosiciones(columns_names)\n",
    "\n",
    "    def CrearImagenSinteticaConColores(self, pixels=20, column_names=None):\n",
    "        matriz = np.ones((pixels, pixels, 3))\n",
    "\n",
    "        colores = mpl.colormaps['tab10'](np.linspace(0, 1, len(column_names)))\n",
    "\n",
    "        if hasattr(self, 'pos_pixel_caract') and self.pos_pixel_caract is not None and column_names is not None:\n",
    "            for i, pos in enumerate(self.pos_pixel_caract):\n",
    "                if i < len(column_names):\n",
    "                    x, y = int(pos[0]), int(pos[1])\n",
    "                    if x < pixels and y < pixels:\n",
    "                        matriz[x, y] = colores[i][:3]\n",
    "\n",
    "        patches = [mpatches.Patch(color=colores[i][:3], label=column_names[i]) for i in range(len(column_names))]\n",
    "\n",
    "        plt.imshow(matriz)\n",
    "        plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.show()\n",
    "\n",
    "modeloIMG = DataImg(algoritmo=\"PCA\", pixeles=pixels, amp=np.pi, distancia=2, pasos=4, opcion='mean', seed=42, veces=4)\n",
    "\n",
    "df_x_wo_img = df_x.copy().drop([\"images\",\"values\"], axis=1)\n",
    "\n",
    "df_x_sec = df_x_wo_img\n",
    "modeloIMG.Entrenamiento(df_x_sec, df_x_sec.columns.values)\n",
    "modeloIMG.CrearImagenSinteticaConColores(pixels=pixels, column_names=df_x_sec.columns.values)\n",
    "modeloIMG.columns_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ja4VtWNmDH8f"
   },
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
    "    grad_model = keras.models.Model(\n",
    "        model.inputs,\n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_output, prediction = grad_model(img_array)\n",
    "        loss = prediction[:, 0]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_output = conv_output[0]\n",
    "    heatmap = conv_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0)\n",
    "    max_val = tf.reduce_max(heatmap)\n",
    "    if max_val > 0:\n",
    "        heatmap /= max_val\n",
    "\n",
    "    return heatmap.numpy()\n",
    "\n",
    "\n",
    "def get_gradcam_feature_importance(\n",
    "    X_num,\n",
    "    X_img,\n",
    "    model,\n",
    "    last_conv_layer_name,\n",
    "    column_coords\n",
    "):\n",
    "    feature_sums = {col: 0.0 for col in X_num.columns}\n",
    "    n_samples = len(X_num)\n",
    "    pixels = X_img.shape[1]\n",
    "\n",
    "    for i in tqdm(range(n_samples), desc=\"Grad‑CAM regression\"):\n",
    "        num_in = np.expand_dims(X_num.iloc[i].values, axis=0)\n",
    "        img_in = np.expand_dims(X_img[i], axis=0)\n",
    "        heatmap = make_gradcam_heatmap([num_in, img_in], model, last_conv_layer_name)\n",
    "\n",
    "        h, w = heatmap.shape\n",
    "\n",
    "        for col, (x, y) in column_coords.items():\n",
    "            hx = int(x / pixels * w)\n",
    "            hy = int(y / pixels * h)\n",
    "            hx = np.clip(hx, 0, w - 1)\n",
    "            hy = np.clip(hy, 0, h - 1)\n",
    "\n",
    "            feature_sums[col] += heatmap[hy, hx]\n",
    "\n",
    "    feature_importance = {col: feature_sums[col] / n_samples for col in feature_sums}\n",
    "    return feature_importance\n",
    "\n",
    "cnn_metrics_path = f'{dataset_path}/cnn_metrics.npy'\n",
    "\n",
    "if not os.path.exists(cnn_metrics_path):\n",
    "  heatmap_metrics = get_gradcam_feature_importance(\n",
    "      X_test_num,\n",
    "      X_test_img,\n",
    "      model,\n",
    "      'conv2d_1',\n",
    "      modeloIMG.columns_coords\n",
    "  )\n",
    "  np.save(cnn_metrics_path, heatmap_metrics, allow_pickle=True)\n",
    "else:\n",
    "  heatmap_metrics = np.load(cnn_metrics_path, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1757269056558,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "YvN40f_aD5ru",
    "outputId": "748566b7-dd44-4ab9-8a26-5b2b976fa69e"
   },
   "outputs": [],
   "source": [
    "heatmap_metrics = {f: (v.numpy() if hasattr(v, \"numpy\") else v) for f, v in heatmap_metrics.items()}\n",
    "\n",
    "min_val, max_val = min(heatmap_metrics.values()), max(heatmap_metrics.values())\n",
    "heatmap_metrics_normalized = {f: (v - min_val) / (max_val - min_val) for f, v in heatmap_metrics.items()}\n",
    "\n",
    "plot_feature_importance_bar(heatmap_metrics_normalized, title=\"Grad-CAM Heatmap Feature Importance\", output_path=f'{dataset_path}/cnn_metrics.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1757269056752,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "35_VLHyyBeMS",
    "outputId": "0f7d772e-1ecc-4f31-facf-4d4750b91f6d"
   },
   "outputs": [],
   "source": [
    "def display_image_with_labels(ax, image, column_coords,\n",
    "                              max_labels_per_pixel=1,\n",
    "                              stack_spacing=0.5,\n",
    "                              max_label_length=11, fontsize=14):\n",
    "    pixels = image.shape[0]\n",
    "    ax.imshow(image)\n",
    "\n",
    "    pixel_map = {}\n",
    "    short_to_long = {}\n",
    "\n",
    "    i = 1\n",
    "    for label, coords in column_coords.items():\n",
    "        row, col = int(coords[0]), int(coords[1])\n",
    "        if 0 <= row < pixels and 0 <= col < pixels:\n",
    "            vname = f\"V{i}\"\n",
    "            pixel_map.setdefault((row, col), []).append((vname, label))\n",
    "            short_to_long[vname] = label\n",
    "            i += 1\n",
    "\n",
    "    def _clamp(v, lo, hi):\n",
    "        return max(lo, min(hi, v))\n",
    "\n",
    "    cluster_id = 0\n",
    "    cluster_map = {}\n",
    "\n",
    "    for (row, col), labels in pixel_map.items():\n",
    "        k = len(labels)\n",
    "\n",
    "        if k <= max_labels_per_pixel:\n",
    "            start_y = row - (k - 1) * stack_spacing / 2.0\n",
    "            for i, (short_name, long_name) in enumerate(labels):\n",
    "                label_text = short_name\n",
    "                if len(label_text) > max_label_length:\n",
    "                    label_text = label_text[:max_label_length-1] + \"…\"\n",
    "\n",
    "                plot_y = start_y + i * stack_spacing\n",
    "                clamped_x = _clamp(col, -0.5, pixels - 0.5)\n",
    "                clamped_y = _clamp(plot_y, -0.5, pixels - 0.5)\n",
    "\n",
    "                ax.text(clamped_x, clamped_y - 1, label_text,\n",
    "                        ha='center', va='center', fontsize=fontsize, zorder=10,\n",
    "                        bbox=dict(facecolor='white', alpha=0.45, edgecolor='none', pad=0.6),\n",
    "                        clip_on=True)\n",
    "\n",
    "        else:\n",
    "            cluster_name = f\"C{cluster_id}\"\n",
    "            cluster_contents = [long for _, long in labels]\n",
    "            cluster_map[cluster_name] = cluster_contents\n",
    "\n",
    "            ax.text(col, row - 1, cluster_name,\n",
    "                    ha='center', va='center', fontsize=fontsize, fontweight='bold', zorder=10,\n",
    "                    bbox=dict(facecolor='white', alpha=0.45, edgecolor='none', pad=0.8),\n",
    "                    clip_on=True)\n",
    "\n",
    "            cluster_id += 1\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    print(\"\\n--- Label Translation Dictionary ---\")\n",
    "    for v, full in short_to_long.items():\n",
    "        print(f\"{v} -> {full}\")\n",
    "    for c, full_list in cluster_map.items():\n",
    "        print(f\"{c} -> {', '.join(full_list)}\")\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    return short_to_long, cluster_map\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "sample_image = X_test_img[10]\n",
    "display_image_with_labels(ax, sample_image, modeloIMG.columns_coords, max_labels_per_pixel=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{dataset_path}/tinto_sample.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgUTHIdeFNYt"
   },
   "outputs": [],
   "source": [
    "def save_and_display_gradcam(img, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0)\n",
    "    max_val = tf.reduce_max(heatmap)\n",
    "    if max_val > 0:\n",
    "        heatmap = heatmap / max_val\n",
    "    heatmap = np.uint8(255 * heatmap.numpy())\n",
    "\n",
    "    jet = plt.get_cmap(\"jet\")\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    superimposed_img.save(cam_path)\n",
    "    return superimposed_img\n",
    "\n",
    "\n",
    "def generate_heatmap_and_image(X_val_num, X_val_img, modelX, layer_name, model_type=\"HYBRID\"):\n",
    "    if model_type == \"HYBRID\":\n",
    "        input_data = [np.expand_dims(X_val_num, axis=0), np.expand_dims(X_val_img, axis=0)]\n",
    "    elif model_type == \"CNN\":\n",
    "        input_data = np.expand_dims(X_val_img, axis=0) / 255.0\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'HYBRID' or 'CNN'.\")\n",
    "\n",
    "    heatmap = make_gradcam_heatmap(input_data, modelX, layer_name)\n",
    "\n",
    "    return save_and_display_gradcam(X_val_img, heatmap)\n",
    "\n",
    "\n",
    "def display_image(ax, row, col, image, title):\n",
    "    axis = ax[row][col] if ax.ndim > 1 else ax[col]\n",
    "    axis.imshow(image)\n",
    "    axis.set_title(title, fontsize=14)\n",
    "    axis.set_xticks([])\n",
    "    axis.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1757269057263,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "0c530KjhBwJR",
    "outputId": "65c2dc97-5011-4227-bb35-6e372ce9ba1c"
   },
   "outputs": [],
   "source": [
    "samples = 1\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 4), squeeze=False)\n",
    "i = 10\n",
    "\n",
    "X_test_data = []\n",
    "label = \"Original Image\"\n",
    "X_test_data.append((X_test_num.iloc[i], X_test_img[i], label))\n",
    "num, img, title = X_test_data[0]\n",
    "display_image(ax, 0, 0, img, title)\n",
    "\n",
    "layer = \"conv2d_1\"\n",
    "superimposed_img = generate_heatmap_and_image(num, img, model, layer, \"HYBRID\")\n",
    "display_title = \"Grad-CAM\"\n",
    "display_image(ax, 0, 1, superimposed_img, display_title)\n",
    "\n",
    "jet_cmap = plt.colormaps['jet']\n",
    "\n",
    "jet_colors = jet_cmap(range(256))\n",
    "jet_colors[:, -1] = 0.4\n",
    "transparent_jet = colors.ListedColormap(jet_colors)\n",
    "\n",
    "norm = colors.Normalize(vmin=0, vmax=1)\n",
    "sm = cm.ScalarMappable(cmap=transparent_jet, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "cbar = fig.colorbar(sm, ax=ax[0, 1], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{dataset_path}/feature_importance_sample.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbS5nDsxFc2N"
   },
   "source": [
    "---\n",
    "## <font color=\"#004D7F\" size=6> 6.3. PermGrad Feature Importance</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WreiKTbYFd_F"
   },
   "outputs": [],
   "source": [
    "joint_importances_named_path = f'{dataset_path}/joint_metrics.npy'\n",
    "\n",
    "if not os.path.exists(joint_importances_named_path):\n",
    "  joint_metrics = {}\n",
    "\n",
    "  print(\"--- Calculating Baseline Performance ---\")\n",
    "  y_probas_baseline = model.predict([X_test_num, X_test_img], verbose=0)\n",
    "  baseline_loss = np.mean(\n",
    "      tf.keras.losses.MSE(y_test, y_probas_baseline)\n",
    "  )\n",
    "  print(f\"Baseline test loss: {baseline_loss:.4f}\\n\")\n",
    "\n",
    "  numeric_input, image_input = model.inputs\n",
    "\n",
    "  mlp_output = model.get_layer('dropout_17').output\n",
    "  cnn_output = model.get_layer('flatten_2').output\n",
    "\n",
    "  def forward_from(layer_name, new_input):\n",
    "      x = new_input\n",
    "      found = False\n",
    "      for layer in model.layers:\n",
    "          if layer.name == layer_name:\n",
    "              found = True\n",
    "              continue\n",
    "          if found:\n",
    "              x = layer(x)\n",
    "      return x\n",
    "\n",
    "  zeros_for_cnn = Lambda(lambda x: tf.zeros_like(x), name='zeros_for_cnn')(cnn_output)\n",
    "  combined_cnn = model.get_layer('concatenate_2')([mlp_output, zeros_for_cnn])\n",
    "\n",
    "  final_output_cnn = forward_from('concatenate_2', combined_cnn)\n",
    "  ablation_model_cnn = Model(\n",
    "      inputs=[numeric_input, image_input], outputs=final_output_cnn\n",
    "  )\n",
    "\n",
    "  y_probas_cnn = ablation_model_cnn.predict([X_test_num, X_test_img], verbose=0)\n",
    "  loss_cnn = np.mean(tf.keras.losses.MSE(y_test, y_probas_cnn).numpy())\n",
    "  joint_metrics[\"CNN\"] = float(loss_cnn - baseline_loss)\n",
    "\n",
    "  print(\"CNN branch ablation:\")\n",
    "  print(f\"  Ablated loss: {loss_cnn:.4f}\")\n",
    "  print(f\"  ΔLoss (Change in Loss): {joint_metrics['CNN']:.4f}\\n\")\n",
    "\n",
    "  zeros_for_mlp = Lambda(lambda x: tf.zeros_like(x), name='zeros_for_mlp')(mlp_output)\n",
    "  combined_mlp = model.get_layer('concatenate_2')([zeros_for_mlp, cnn_output])\n",
    "\n",
    "  final_output_mlp = forward_from('concatenate_2', combined_mlp)\n",
    "  ablation_model_mlp = Model(\n",
    "      inputs=[numeric_input, image_input], outputs=final_output_mlp\n",
    "  )\n",
    "\n",
    "  y_probas_mlp = ablation_model_mlp.predict([X_test_num, X_test_img], verbose=0)\n",
    "  loss_mlp = np.mean(tf.keras.losses.MSE(y_test, y_probas_mlp).numpy())\n",
    "  joint_metrics[\"MLP\"] = float(loss_mlp - baseline_loss)\n",
    "\n",
    "  print(\"MLP branch ablation:\")\n",
    "  print(f\"  Ablated loss: {loss_mlp:.4f}\")\n",
    "  print(f\"  ΔLoss (Change in Loss): {joint_metrics['MLP']:.4f}\\n\")\n",
    "\n",
    "  print(\"ΔLoss Results Dictionary:\")\n",
    "  print(joint_metrics)\n",
    "\n",
    "  all_values = list(joint_metrics.values())\n",
    "  den = sum(math.exp(v) for v in all_values)\n",
    "  joint_metrics = {b: math.exp(v) / den for b, v in joint_metrics.items()}\n",
    "\n",
    "  np.save(joint_importances_named_path, joint_metrics, allow_pickle=True)\n",
    "else:\n",
    "  joint_metrics = np.load(joint_importances_named_path, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Branch Importance:\")\n",
    "print(joint_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxTS5t8GYQVx"
   },
   "outputs": [],
   "source": [
    "perm_grad_mlp_importances_normalized = {\n",
    "    feature: joint_metrics[\"MLP\"] * val\n",
    "                  for feature, val in mlp_importances_normalized.items()\n",
    "}\n",
    "\n",
    "perm_grad_heatmap_metrics_normalized = {\n",
    "    feature: joint_metrics[\"CNN\"] * val\n",
    "                  for feature, val in heatmap_metrics_normalized.items()\n",
    "}\n",
    "\n",
    "global_importance_by_branch = {}\n",
    "\n",
    "for feature in perm_grad_mlp_importances_normalized.keys():\n",
    "    global_importance_by_branch[feature] = perm_grad_mlp_importances_normalized[feature] + perm_grad_heatmap_metrics_normalized[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1757269057777,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "Y6f4EmkQGLFc",
    "outputId": "a4c7caf9-f9cd-4131-88d5-8d9910f7382a"
   },
   "outputs": [],
   "source": [
    "plot_feature_importance_bar(global_importance_by_branch, title=\"\", output_path=f'{dataset_path}/permgrad.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1757269084334,
     "user": {
      "displayName": "Felipe Escalera Gonzalez",
      "userId": "16752102397912297330"
     },
     "user_tz": -120
    },
    "id": "EMJ58-G9ZZkg",
    "outputId": "584a70ec-abd0-4e0c-9e31-d8bcae6231f4"
   },
   "outputs": [],
   "source": [
    "global_importance_by_branch\n",
    "\n",
    "result = {}\n",
    "for key, value in global_importance_by_branch.items():\n",
    "    result[key] = result.get(key, 0) + value\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
